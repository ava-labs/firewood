# Triggers AvalancheGo's C-Chain reexecution benchmark and publishes
# results to GitHub Pages for trend analysis.
name: C-Chain Reexecution Performance Tracking

on:
  schedule:
    # Daily at 05:00 UTC (00:00 ET) - 1M blocks: 40M → 41M
    - cron: '0 5 * * *'
    # Weekly Sunday at 05:00 UTC (00:00 ET) - 10M blocks: 50M → 60M
    - cron: '0 5 * * 0'
  workflow_dispatch:
    inputs:
        default: ''
      avalanchego:
        description: 'AvalancheGo commit/branch/tag to test against'
        default: 'master'
      test:
        description: 'Predefined test (leave empty to use custom parameters below)' # https://github.com/ava-labs/avalanchego/blob/a85295d87193b30ff17c594680dadd6618022f5e/scripts/benchmark_cchain_range.sh#L63
        default: ''
      config:
        description: 'Config (e.g., firewood, hashdb)'
        default: ''
      start-block:
        default: ''
      end-block:
        default: ''
      block-dir-src:
        description: 'Block directory source (e.g., cchain-mainnet-blocks-1m-ldb [without S3 path])'
        default: ''
      current-state-dir-src:
        description: 'Current state directory source (e.g., cchain-mainnet-blocks-30m-40m-ldb [without S3 path])'
        default: ''
      runner:
        description: 'Runner to use in AvalancheGo'
        required: true
        type: choice
        options:
          - avalanche-avalanchego-runner-2ti
          - avago-runner-i4i-4xlarge-local-ssd
          - avago-runner-m6i-4xlarge-ebs-fast
      timeout-minutes:
        description: 'Timeout in minutes'
        default: ''

jobs:
  resolve-config:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.resolve.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4
      - name: Resolve benchmark config
        id: resolve
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let matrix;

            if (context.eventName === 'schedule') {
              const cron = context.payload.schedule;
              const config = JSON.parse(fs.readFileSync('.github/benchmark-schedules.json', 'utf8'));
              const matches = config.schedule.include.filter(c => c.cron.toLowerCase() === cron.toLowerCase());
              if (matches.length === 0) {
                core.setFailed(`No configuration found for schedule: ${cron}`);
                return;
              }
              matrix = { include: matches };
            } else {
              matrix = {
                include: [{
                  name: 'manual',
                  test: '${{ inputs.test }}',
                  config: '${{ inputs.config }}',
                  'start-block': '${{ inputs.start-block }}',
                  'end-block': '${{ inputs.end-block }}',
                  'block-dir-src': '${{ inputs.block-dir-src }}',
                  'current-state-dir-src': '${{ inputs.current-state-dir-src }}',
                  runner: '${{ inputs.runner }}',
                  'timeout-minutes': '${{ inputs.timeout-minutes }}'
                }]
              };
            }

            core.setOutput('matrix', JSON.stringify(matrix));
            console.log('Matrix:', JSON.stringify(matrix, null, 2));

  benchmark:
    needs: resolve-config
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Required for github-action-benchmark to push to gh-pages
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.resolve-config.outputs.matrix) }}
    steps:
      # NOTE: This checkout is only to get the bench-cchain-reexecution.sh script.
      # We're not building or testing Firewood here—the script triggers AvalancheGo's
      # workflow via API and passes FIREWOOD_REF to it. AvalancheGo is responsible
      # for checking out and building Firewood at that ref.
      - name: Checkout Firewood
        uses: actions/checkout@v4

      - name: Trigger C-Chain Reexecution Benchmark
        run: |
          if [[ -n "${{ matrix.test }}" ]]; then
            ./scripts/bench-cchain-reexecution.sh trigger "${{ matrix.test }}"
          else
            ./scripts/bench-cchain-reexecution.sh trigger
          fi
        env:
          GH_TOKEN: ${{ secrets.FIREWOOD_AVALANCHEGO_GITHUB_TOKEN }}
          # Custom mode (ignored when test is specified)
          CONFIG: ${{ matrix.config }}
          START_BLOCK: ${{ matrix.start-block }}
          END_BLOCK: ${{ matrix.end-block }}
          BLOCK_DIR_SRC: ${{ matrix.block-dir-src }}
          CURRENT_STATE_DIR_SRC: ${{ matrix.current-state-dir-src }}
          # Refs
          FIREWOOD_REF: ${{ matrix.firewood || github.sha }}
          AVALANCHEGO_REF: ${{ matrix.avalanchego }}
          LIBEVM_REF: ${{ matrix.libevm }}
          # Execution
          RUNNER: ${{ matrix.runner }}
          TIMEOUT_MINUTES: ${{ matrix.timeout-minutes }}

      # github.ref controls where results are stored (not what gets benchmarked):
      # - main branch → bench/ (official history)
      # - feature branches → dev/bench/{branch}/ (experimental, won't pollute trends)
      # inputs.firewood controls what gets benchmarked (passed to AvalancheGo).
      - name: Determine results location
        id: location
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "data-dir=bench" >> "$GITHUB_OUTPUT"
          else
            echo "data-dir=dev/bench/$(echo '${{ github.ref_name }}' | tr '/' '-')" >> "$GITHUB_OUTPUT"
          fi

      - name: Publish benchmark results
        id: store
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: C-Chain Reexecution with Firewood
          tool: 'customBiggerIsBetter'
          output-file-path: ./results/benchmark-output.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          summary-always: true
          auto-push: true
          fail-on-alert: true
          comment-on-alert: false
          gh-pages-branch: benchmark-data
          benchmark-data-dir-path: ${{ steps.location.outputs.data-dir }}

      - name: Summary
        run: |
          [[ "${{ steps.store.outcome }}" == "failure" ]] && echo "::warning::Benchmark storage failed"
          
          {
            echo "## Benchmark: ${{ matrix.name }}"
            echo
            if [[ -n "${{ matrix.test }}" ]]; then
              echo "| Parameter | Value |"
              echo "|-----------|-------|"
              echo "| Test | \`${{ matrix.test }}\` |"
            else
              echo "| Parameter | Value |"
              echo "|-----------|-------|"
              echo "| Config | \`${{ matrix.config }}\` |"
              echo "| Blocks | \`${{ matrix.start-block }}\` → \`${{ matrix.end-block }}\` |"
              echo "| Block source | \`${{ matrix.block-dir-src }}\` |"
              echo "| State source | \`${{ matrix.current-state-dir-src }}\` |"
            fi
            echo "| Firewood | \`${{ matrix.firewood || github.sha }}\` |"
            echo "| AvalancheGo | \`${{ matrix.avalanchego || 'master' }}\` |"
            echo "| libevm | \`${{ matrix.libevm || '-' }}\` |"
            echo "| Runner | \`${{ matrix.runner }}\` |"
            echo
            echo "[View trends](https://ava-labs.github.io/firewood/${{ steps.location.outputs.data-dir }}/)"
          } >> "$GITHUB_STEP_SUMMARY"

